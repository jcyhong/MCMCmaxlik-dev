#' Compute the MLE given a BUGS model
#'
#' This function computes the MLE of the top-level parameters of a
#' hierarchical model with latent variables.
#' @param model a nimble model object
#' @param paramNodes a character vector indicating the top-level parameters
#' @param method a string indicating the optimization strategy
#' @param paramInit the initial starting point
#' @param compiledFuns a list of compiled function, generated by buildMCMCmaxlik()
#' @keywords MLE
#' @export
#' @examples
#' compileMLE()

computeMLE <- function(model, paramNodes, method="fixed", paramInit=NULL,
                       compiledFuns=NULL, ...) {
  if(is.null(paramInit)) {
    paramInit <- rep(1, length(paramNodes))
  }
  if(!is.null(compiledFuns)) {
    switch(method,
           fixed = gaFixedMLE(model=model, paramNodes=paramNodes,
                              compiledFuns=compiledFuns, paramInit=paramInit,
                              ...),
           NR = NRMLE(model=model, paramNodes=paramNodes,
                      compiledFuns=compiledFuns, paramInit=paramInit,
                      ...),
           adagrad = adagradMLE(model=model, paramNodes=paramNodes,
                                compiledFuns=compiledFuns, paramInit=paramInit,
                                ...),
           adadelta = adadeltaMLE(model=model, paramNodes=paramNodes,
                                  compiledFuns=compiledFuns, paramInit=paramInit,
                                  ...),
           adam = adamMLE(model=model, paramNodes=paramNodes, paramInit=paramInit,
                          compiledFuns=compiledFuns, ...),
           ga1D = ga1DMLE(model=model, paramNodes=paramNodes, paramInit=paramInit,
                          compiledFuns=compiledFuns, ...))
  }
}


# Check if the update is out of range.
checkOutOfRange <- function(thetaNew, boundary) {
  outOfRange <- F
  for (i in 1:length(thetaNew)) {
    if (thetaNew[i] < boundary[[i]][1]) {
      outOfRange <- T
      break
    }
    else if (thetaNew[i] > boundary[[i]][2]) {
      outOfRange <- T
      break
    }
  }
  return(outOfRange)
}

gaFixedMLE <- function(model, paramNodes, compiledFuns, paramInit, boundary,
                       postMode = F, 
                       burninFrac = 0.5,
                       stepsize = 1, maxIter = 100, numMCMCSamples = 10000, 
                       delta = 1e-04, tol = 1e-04) {
  thetaCur <- paramInit
  thetaNew <- paramInit
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter, ncol = length(paramInit))
  paramMatrix[1, ] <- paramInit
  while (iter < maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    gradCurr <- compiledFuns$computeGrad$grad
    eta <- stepsize
    thetaNew <- paramMatrix[iter, ] + eta * gradCurr
    print(eta * gradCurr)
    print(thetaNew)
    # Check boundaries. (Projected)
    if (any(is.na(thetaNew))) {
      break
    }
    for (i in 1:length(paramNodes)) {
      if (thetaNew[i] < boundary[[i]][1]) {
        thetaNew[i] = boundary[[i]][1]
      }
      else if (thetaNew[i] > boundary[[i]][2]) {
        thetaNew[i] = boundary[[i]][2]
      }
      else {
        thetaNew[i] = thetaNew[i]
      }
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thr <- sum((gradCurr)^2)
    thetaCur <- thetaNew
    compiledFuns$setLatent$run(tail(as.matrix(compiledFuns$MCMC$mvSamples), 1))
    iter <- iter + 1
    print(iter)
  }
  return(list(param = paramMatrix, iter = iter))
}

NRMLE <- function(model, paramNodes, compiledFuns, paramInit, boundary=NULL,
                  postMode = F, burninFrac = 0.5,
                  stepsize = 1, maxIter = 100, numMCMCSamples = 10000, 
                  delta = 1e-04, tol = 1e-04) {
  
  if(is.null(boundary)){
    boundary=vector('list',length(paramNodes))
    for(i in 1:length(paramNodes)){
      boundary[[i]]=c(getBound(model,paramNodes[i],'lower'),
                      getBound(model,paramNodes[i],'upper'))
    }
  }
  
  thetaCur <- paramInit
  thetaNew <- paramInit
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter, ncol = length(paramInit))
  paramMatrix[1, ] <- paramInit
  
  while (iter < maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    ## add warm up
    warmUp <- unname(as.matrix(compiledFuns$MCMC$mvSamples)[numMCMCSamples,])
    compiledFuns$setLatent$run(warmUp)
    gradCurr <- compiledFuns$computeGrad$grad
    print(gradCurr)
    approxHessian <- compiledFuns$computeHess$run(1e-4, postMode)
    move <- solve(approxHessian, gradCurr)
    thetaNew <- paramMatrix[iter, ] - move
    s <- 1
    #print(thetaNew)
    while (checkOutOfRange(thetaNew, boundary)) {
      thetaNew <- paramMatrix[iter, ] - 0.8^s * move
      s <- s + 1
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thr <- sum((gradCurr)^2)
    thetaCur <- thetaNew
    print(thetaCur)
    iter <- iter + 1
    print(iter)
  }
  return(list(param = paramMatrix, iter = iter, hess = approxHessian))
}


adagradMLE <- function(model, paramNodes, compiledFuns, paramInit, boundary,
                       postMode = F, maxIter = 100,
                       burninFrac = 0.5,
                       numMCMCSamples = 10000, 
                       eta=0.01, delta = 1e-04, eps = 1e-2,
                       tol = 1e-04) {
  thetaCur <- paramInit
  thetaNew <- paramInit
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter, ncol = length(paramInit))
  accumGrad <- numeric(length(paramInit))
  paramMatrix[1, ] <- paramInit
  while (iter < maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    gradCurr <- compiledFuns$computeGrad$grad
    accumGrad <- accumGrad + (gradCurr ^ 2)
    RMSGrad <- sqrt(accumGrad + eps)
    updateCurr <- eta / RMSGrad * gradCurr
    thetaNew <- paramMatrix[iter, ] + updateCurr
    print(eta / RMSGrad * gradCurr)
    print(thetaNew)
    # Check boundaries. (Projected)
    if (any(is.na(thetaNew))) {
      break
    }
    for (i in 1:length(paramNodes)) {
      if (thetaNew[i] < boundary[[i]][1]) {
        thetaNew[i] = boundary[[i]][1]
      }
      else if (thetaNew[i] > boundary[[i]][2]) {
        thetaNew[i] = boundary[[i]][2]
      }
      else {
        thetaNew[i] = thetaNew[i]
      }
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thr <- sum((gradCurr)^2)
    thetaCur <- thetaNew
    compiledFuns$setLatent$run(tail(as.matrix(compiledFuns$MCMC$mvSamples), 1))
    iter <- iter + 1
    print(iter)
  }
  return(list(param = paramMatrix, iter = iter))
}


adadeltaMLE <- function(model, paramNodes, compiledFuns, paramInit, boundary,
                        postMode = F, maxIter = 100, numMCMCSamples = 10000, 
                        trackEffSizeGrad = F,
                        burninFrac = 0.5,
                        delta = 1e-04, tol = 1e-04, eps = 1e-2, rho=0.9) {
  thetaCur <- paramInit
  thetaNew <- paramInit
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter + 1, ncol = length(paramInit))
  if (trackEffSizeGrad) {
    latentNodes <- model$getNodeNames(latentOnly = TRUE, stochOnly = TRUE)
    effSizesGrad <- matrix(nrow = maxIter, ncol = length(latentNodes))
  }
  accumGrad <- numeric(length(paramInit))
  accumUpdate <- numeric(length(paramInit))
  paramMatrix[1, ] <- paramInit
  while (iter <= maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    gradCurr <- compiledFuns$computeGrad$grad
    accumGrad <- rho * accumGrad + (1 - rho) * (gradCurr ^ 2)
    RMSGrad <- sqrt(accumGrad + eps)
    RMSUpdate <- sqrt(accumUpdate + eps)
    updateCurr <-  RMSUpdate / RMSGrad * gradCurr
    thetaNew <- paramMatrix[iter, ] + updateCurr
    print(RMSUpdate / RMSGrad * gradCurr)
    print(thetaNew)
    accumUpdate <- rho * accumUpdate + (1 - rho) * (updateCurr ^ 2)
    # Check boundaries. (Projected)
    if (any(is.na(thetaNew))) {
      break
    }
    for (i in 1:length(paramNodes)) {
      if (thetaNew[i] < boundary[[i]][1]) {
        thetaNew[i] = boundary[[i]][1]
      }
      else if (thetaNew[i] > boundary[[i]][2]) {
        thetaNew[i] = boundary[[i]][2]
      }
      else {
        thetaNew[i] = thetaNew[i]
      }
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thr <- sum((gradCurr)^2)
    thetaCur <- thetaNew
    compiledFuns$setLatent$run(tail(as.matrix(compiledFuns$MCMC$mvSamples), 1))
    
    df <- data.frame(t(thetaCur))
    names(df) <- paramNodes
    cat(paste0("Iteration Number: ", iter, ".\n",
               "Parameter Estimates:\n"))
    print(df, row.names = FALSE)
    if (trackEffSizeGrad) {
      samplesGrad <- as.matrix(compiledFuns$MCMC$mvSamples)
      samplesGrad <- samplesGrad[(ceiling(burninFrac * numMCMCSamples) + 1):numMCMCSamples,]
      
      effSizesGrad[iter,] <- round(effectiveSize(samplesGrad), 1)
      cat(paste0("Effective Sample Size for gradient (raw, min): ", 
                 min(effSizesGrad[iter, ]), 
                 "\n")) 
    }
    iter <- iter + 1
  }
  if (trackEffSizeGrad) {
    results <- list(param = paramMatrix, iter = iter, effSizesGrad = effSizesGrad)
  } else {
    results <- list(param = paramMatrix, iter = iter)
  }
  return(results)
}

adamMLE <- function(model, paramNodes, compiledFuns, paramInit, boundary,
                    postMode = F, trackEffSizeGrad = F,
                    maxIter = 100, numMCMCSamples = 10000, 
                    delta = 1e-04, tol = 1e-04, eps = 1e-8,
                    burninFrac = 0.5,
                    stepsize=0.001,
                    beta1=0.9, beta2=0.999) {
  thetaCur <- paramInit
  thetaNew <- paramInit
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter + 1, ncol = length(paramInit))
  if (trackEffSizeGrad) {
    latentNodes <- model$getNodeNames(latentOnly = TRUE, stochOnly = TRUE)
    effSizesGrad <- matrix(nrow = maxIter, ncol = length(latentNodes))
  }
  accumFirst <- numeric(length(paramInit))
  accumSecond <- numeric(length(paramInit))
  paramMatrix[1, ] <- paramInit
  while (iter <= maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)

    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    gradCurr <- compiledFuns$computeGrad$grad
    accumFirst <- beta1 * accumFirst + (1 - beta1) * (gradCurr)
    accumSecond <- beta2 * accumSecond + (1 - beta2) * (gradCurr^2)
    accumFirstAdj <- accumFirst / (1 - beta1^iter)
    accumSecondAdj <- accumSecond / (1 - beta2^iter)
    updateCurr <-  stepsize / (sqrt(accumSecondAdj) + eps) * accumFirstAdj
    thetaNew <- paramMatrix[iter, ] + updateCurr
    # Check boundaries. (Projected)
    if (any(is.na(thetaNew))) {
      break
    }
    for (i in 1:length(paramNodes)) {
      if (thetaNew[i] < boundary[[i]][1]) {
        thetaNew[i] = boundary[[i]][1]
      }
      else if (thetaNew[i] > boundary[[i]][2]) {
        thetaNew[i] = boundary[[i]][2]
      }
      else {
        thetaNew[i] = thetaNew[i]
      }
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thr <- sum((gradCurr)^2)
    thetaCur <- thetaNew
    compiledFuns$setLatent$run(tail(as.matrix(compiledFuns$MCMC$mvSamples), 1))
    
    df <- data.frame(t(thetaCur))
    names(df) <- paramNodes
    cat(paste0("Iteration Number: ", iter, ".\n",
               "Parameter Estimates:\n"))
    print(df, row.names = FALSE)
    if (trackEffSizeGrad) {
      samplesGrad <- as.matrix(compiledFuns$MCMC$mvSamples)
      samplesGrad <- samplesGrad[(ceiling(burninFrac * numMCMCSamples) + 1):numMCMCSamples,]
      
      effSizesGrad[iter,] <- round(effectiveSize(samplesGrad), 1)
      cat(paste0("Effective Sample Size for gradient (raw, min): ", 
                 min(effSizesGrad[iter, ]), 
                 "\n")) 
    }
    iter <- iter + 1
  }
  if (trackEffSizeGrad) {
    results <- list(param = paramMatrix, iter = iter, effSizesGrad = effSizesGrad)
  } else {
    results <- list(param = paramMatrix, iter = iter)
  }
  return(results)
}

getKernelMode <- function(samples, kern="gaussian", bdwth="nrd0",adjust) {
  d <- density(samples, bw=bdwth, kernel=kern,adjust=adjust)
  modeR<-d$x[which.max(d$y)]
  return(modeR)
}

ga1DMLE <- function(model, paramNodes, compiledFuns, paramInit, 
                    postMode=F, maxIter=100,
                    numMCMCSamples=300, numMCMCSamples1D=300, 
                    delta = 1e-04,
                    burninFrac=0.5, burninFrac1D=0.5,
                    tol=1e-04, boundary=NULL) {
  if(is.null(boundary)){
    boundary=vector('list',length(paramNodes))
    for(i in 1:length(paramNodes)){
      boundary[[i]] <-
        c(getBound(model,paramNodes[i],'lower'),
          getBound(model,paramNodes[i],'upper'))
    }
  }
  
  compiledFuns$decideIncludePrior$run(postMode)
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow = maxIter + 1, ncol = length(paramInit))
  effSizes <- numeric(length = maxIter)
  latentNodes <- model$getNodeNames(latentOnly = TRUE, stochOnly = TRUE)
  effSizesGrad <-matrix(nrow = maxIter, ncol = length(latentNodes))
  # gelmanStat <- numeric(length = maxIter)
  paramMatrix[1, ] <- paramInit
  
  while (iter <= maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    
    samplesGrad <- as.matrix(compiledFuns$MCMC$mvSamples)
    samplesGrad <- samplesGrad[(ceiling(burninFrac * numMCMCSamples) + 1):numMCMCSamples,]
    
    effSizesGrad[iter,] <- round(effectiveSize(samplesGrad), 1)
    
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    
    warmUp <- unname(as.matrix(compiledFuns$MCMC$mvSamples)[numMCMCSamples,])
    compiledFuns$setLatent$run(warmUp)
    
    compiledFuns$MCMC1D$run(numMCMCSamples1D)
    samples1D <- as.matrix(compiledFuns$MCMC1D$mvSamples)
    gradCurr <- compiledFuns$computeGrad$grad
    samplesb <- (samples1D[, 1] - paramMatrix[iter, 1]) / gradCurr[1]
    ### burn in
    burn.in <- ceiling(burninFrac1D * numMCMCSamples1D)
    samplesb <- samplesb[(burn.in+1):numMCMCSamples1D]
    effSizes[iter + 1] <- effectiveSize(samplesb)
    # account for dependence of samples
    stepsize <- getKernelMode(samplesb,
                              adjust=(numMCMCSamples1D / 
                                        (effSizes[iter] + 1))^(1/5))
    
    thetaCurr <- paramMatrix[iter, ] + stepsize * gradCurr
    # Check boundaries. (Projected)
    
    for (i in 1:length(paramNodes)) {
      
      if (thetaCurr[i] < boundary[[i]][1]) {
        thetaCurr[i] = boundary[[i]][1]
      }
      else if (thetaCurr[i] > boundary[[i]][2]) {
        thetaCurr[i] = boundary[[i]][2]
      }
      else {
        thetaCurr[i] = thetaCurr[i]
      }
    }
    
    paramMatrix[iter + 1, ] <- thetaCurr
    thr <- sum((gradCurr)^2)
    
    df <- data.frame(t(thetaCurr))
    names(df) <- paramNodes
    cat(paste0("Iteration Number: ", iter, ".\n",
                 "Parameter Estimates:\n"))
    print(df, row.names = FALSE)
    cat(paste0("Effective Sample Size for gradient (raw, min): ", 
               min(effSizesGrad[iter, ]), 
               "\n"))
    cat(paste0("Effective Sample Size for 1D sampling: ", effSizes[iter], "\n"))
    iter <- iter + 1
  }
  
  approxHessian <- compiledFuns$computeHess$run(1e-4, postMode, burninFrac)
  return(list(param=paramMatrix,
              iter=iter, 
              effSizes=effSizes,
              effSizesGrad=effSizesGrad,
              hess=approxHessian))
}