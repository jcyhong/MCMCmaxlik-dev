#' Compute the MLE using fixed stepsize gradient ascent.
#'
#' This function computes the MLE of the top-level parameters of a
#' hierarchical model with latent variables using Adam.
#' @param model a nimble model object
#' @param paramNodes a character vector indicating the top-level parameters
#' @param compiledFuns a list of compiled function, generated by buildMCMCmaxlik()
#' @param paramInit the initial starting point
#' @param boundary the range of the top-level parameters, 
#' default to using getBound() 
#' @param postMode a boolean indicating whether to include prior in the calculation
#' @param trackEffSizeGrad a boolean indicating whether effective size of the MCMC
#' samples is checked
#' @param maxIter maximum number of iterations
#' @param numMCMCSamples MCMC sample size for gradient computation
#' @param burninFrac the fraction of burn-in samples for gradient computation
#' @param stepsize the step size
#' @param blockSize the size of blocks for convergence checking
#' @param runsThreshold the cutoff for acceptable number of runs within a block
#' of iterates
#' @param pValsThreshold the cutoff of p-value threshold for comparing
#' averages between two blocks of iterates
#' @keywords MLE
#' @export
#' @examples
#' gaFixedMLE()

gaFixedMLE <- function(model, paramNodes, compiledFuns, paramInit, 
                       boundary=NULL,
                       postMode = FALSE, 
                       burninFrac = 0.5,
                       stepsize = 1, maxIter = 100, 
                       numMCMCSamples = 300,
                       trackEffSizeGrad=FALSE,
                       skipConvCheck=FALSE,
                       runUntilMaxIter=TRUE,
                       blockSize = 20, runsThreshold = floor(blockSize / 5),
                       pValThreshold = 0.3) {
  
  ptm <- proc.time()
  
  if (skipConvCheck) {
    blockSize <- maxIter
  }
  if (is.null(boundary)) {
    boundary=vector('list',length(paramNodes))
    for(i in 1:length(paramNodes)){
      boundary[[i]] <-
        c(getBound(model,paramNodes[i],'lower'),
          getBound(model,paramNodes[i],'upper'))
    }
  }
  
  if (trackEffSizeGrad) {
    latentNodes <- model$getNodeNames(latentOnly = TRUE, stochOnly = TRUE)
    effSizesGrad <- matrix(nrow = maxIter, ncol = length(latentNodes))
  }
  
  thetaCur <- paramInit
  thetaNew <- paramInit
  converge <- F
  iter <- 1
  paramMatrix <- matrix(nrow = maxIter + 1, ncol = length(paramInit))
  paramMatrix[1, ] <- paramInit

  while (iter <= maxIter) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    compiledFuns$computeGradHess$run(postMode, burninFrac, gradient = TRUE, hessian = FALSE)
    gradCurr <- compiledFuns$computeGradHess$grad
    print(gradCurr)
    eta <- stepsize
    thetaNew <- paramMatrix[iter, ] + eta * gradCurr
    # Check boundaries. (Projected)
    if (any(is.na(thetaNew))) {
      break
    }
    for (i in 1:length(paramNodes)) {
      if (thetaNew[i] < boundary[[i]][1]) {
        thetaNew[i] = boundary[[i]][1]
      }
      else if (thetaNew[i] > boundary[[i]][2]) {
        thetaNew[i] = boundary[[i]][2]
      }
      else {
        thetaNew[i] = thetaNew[i]
      }
    }
    paramMatrix[iter + 1, ] <- thetaNew
    thetaCur <- thetaNew
    compiledFuns$setLatent$run(tail(as.matrix(compiledFuns$MCMC$mvSamples), 1))
    
    df <- data.frame(t(thetaCur))
    names(df) <- paramNodes
    cat(paste0("Iteration Number: ", iter, ".\n",
               "Parameter Estimates:\n"))
    print(df, row.names = FALSE)
    if (trackEffSizeGrad) {
      samplesGrad <- as.matrix(compiledFuns$MCMC$mvSamples)
      samplesGrad <- samplesGrad[
        (ceiling(burninFrac * numMCMCSamples) + 1):numMCMCSamples, ]
      
      effSizesGrad[iter, ] <- round(effectiveSize(samplesGrad), 1)
      cat(paste0("Effective Sample Size for gradient (raw, min): ", 
                 min(effSizesGrad[iter, ]), 
                 "\n")) 
    }
    
    iter <- iter + 1
    
    # Convergence test
    if (!converge & iter > 2 * blockSize) {
      # 1. Check oscillating behaviors.
      runsResults <- checkRuns(paramMatrix[(iter - blockSize):(iter - 1), ],
                               runsThreshold)
      if (runsResults$pass) {
        # 2. Check whether the average stays constant.
        blockResults <- checkBlocks(
          paramMatrix[(iter - 2 * blockSize):(iter - blockSize - 1), ],
          paramMatrix[(iter - blockSize):(iter - 1), ],
          pValThreshold)
        if (blockResults$pass) {
          convergence.time <- proc.time() - ptm
          convergence.iter <- iter - 1
          converge <- T
          if (!runUntilMaxIter) break
        }
      }
    }
  }
  
  if (!skipConvCheck & iter > 2 * blockSize) {
    cat("*** Convergence diagnostics ***\n")
    if (converge) {
      cat(paste0("Converged at Iteration ", convergence.iter, "\n")) 
    }
    cat(paste0("Number(s) of runs (block size = ", blockSize, "): ", 
               paste0(runsResults$numRuns, collapse=", "),
               "\n"))
    if (runsResults$pass) {
      cat(paste0("p-value from 2-sample t-test for block comparisons: ",
                 paste(round(blockResults$pVal, 3), collapse=", "),
                 "\n")) 
    }
    
    if (!converge) {
      cat("*** Warning: Non-convergence ***\n")
      cat("Use a different starting point or increase the MCMC sample size.\n")
    }
  }
  
  paramMatrix <- na.omit(paramMatrix)
  if (iter > 20) {
    if (converge) {
      MLE <- apply(paramMatrix[(convergence.iter - 19):(convergence.iter), ], 2, mean, trim=.2)
    } else {
      MLE <- apply(tail(paramMatrix, 20), 2, mean, trim=.2)
    }
  } else {
    MLE <- tail(paramMatrix, 1)[1,]
  }
  
  results <- list(param = paramMatrix,
                  MLE = MLE, 
                  execution.time=proc.time() - ptm,
                  execution.iter=iter - 1)
  if (trackEffSizeGrad) {
    results <- c(results, list(effSizesGrad = effSizesGrad))
  }
  if (!skipConvCheck & iter > 2 * blockSize & converge) {
    results <- c(results, 
                 list(convergence.time=convergence.time,
                      convergence.iter=convergence.iter))
  }
  return(results)
}