#' Compute the MLE using 1D sampling.
#'
#' This function computes the MLE of the top-level parameters of a
#' hierarchical model with latent variables using 1D sampling.
#' @param model a nimble model object
#' @param paramNodes a character vector indicating the top-level parameters
#' @param compiledFuns a list of compiled function, generated by 
#' buildMCMCmaxlik()
#' @param paramInit the initial starting point
#' @param postMode a boolean indicating whether to include prior in the 
#' calculation
#' @param maxIter maximum number of iterations
#' @param numMCMCSamples MCMC sample size for gradient approximation
#' @param numMCMCSamples1D MCMC sample size for 1D sampling
#' @param delta finite element differences
#' @param burninFrac the fraction of burn-in samples for gradient approximation
#' @param burninFrac1D the fraction of burn-in samples for 1D sampling
#' @param tol the tolerance
#' @param boundary the range of the top-level parameters, 
#' default to using getBound() 
#' @keywords MLE
#' @export

ga1DMLE <- function(model, paramNodes, compiledFuns, paramInit,
                    boundary=NULL,
                    postMode=F, maxIter=100,
                    numMCMCSamples=300, numMCMCSamples1D=300, 
                    delta=1e-04,
                    burninFrac=0.5, burninFrac1D=0.5,
                    kern="gaussian", bdwth="nrd0",
                    tol=1e-04,
                    blockSize = 20, runsThreshold = floor(blockSize / 5),
                    pValThreshold = 0.3,
                    returnHess = F) {
  if(is.null(boundary)){
    boundary=vector('list',length(paramNodes))
    for(i in 1:length(paramNodes)){
      boundary[[i]] <-
        c(getBound(model,paramNodes[i],'lower'),
          getBound(model,paramNodes[i],'upper'))
    }
  }
  
  compiledFuns$decideIncludePrior$run(postMode)
  iter <- 1
  thr <- Inf
  paramMatrix <- matrix(nrow=maxIter + 1, ncol=length(paramInit))
  effSizes <- numeric(length=maxIter)
  latentNodes <- model$getNodeNames(latentOnly=TRUE, stochOnly=TRUE)
  effSizesGrad <-matrix(nrow=maxIter, ncol=length(latentNodes))
  # gelmanStat <- numeric(length=maxIter)
  paramMatrix[1, ] <- paramInit
  
  while (iter <= maxIter & thr > tol) {
    compiledFuns$setParams$run(paramMatrix[iter, ])
    compiledFuns$MCMC$run(numMCMCSamples)
    
    samplesGrad <- as.matrix(compiledFuns$MCMC$mvSamples)
    samplesGrad <- 
      samplesGrad[(ceiling(burninFrac * numMCMCSamples) + 1):numMCMCSamples,]
    
    effSizesGrad[iter,] <- round(effectiveSize(samplesGrad), 1)
    
    compiledFuns$computeGrad$run(delta, postMode, burninFrac)
    
    warmUp <- unname(as.matrix(compiledFuns$MCMC$mvSamples)[numMCMCSamples,])
    compiledFuns$setLatent$run(warmUp)
    
    compiledFuns$MCMC1D$run(numMCMCSamples1D)
    samples1D <- as.matrix(compiledFuns$MCMC1D$mvSamples)
    gradCurr <- compiledFuns$computeGrad$grad
    samplesb <- (samples1D[, 1] - paramMatrix[iter, 1]) / gradCurr[1]
    ### burn in
    burn.in <- ceiling(burninFrac1D * numMCMCSamples1D)
    samplesb <- samplesb[(burn.in+1):numMCMCSamples1D]
    effSizes[iter + 1] <- effectiveSize(samplesb)
    # account for dependence of samples
    stepsize <- getKernelMode(samplesb,
                              adjust=(numMCMCSamples1D / 
                                        (effSizes[iter] + 1))^(1/5),
                              kern=kern, bdwth=bdwth)
    
    thetaCurr <- paramMatrix[iter, ] + stepsize * gradCurr
    # Check boundaries. (Projected)
    
    for (i in 1:length(paramNodes)) {
      
      if (thetaCurr[i] < boundary[[i]][1]) {
        thetaCurr[i] <- boundary[[i]][1]
      }
      else if (thetaCurr[i] > boundary[[i]][2]) {
        thetaCurr[i] <- boundary[[i]][2]
      }
      else {
        thetaCurr[i] <- thetaCurr[i]
      }
    }
    
    paramMatrix[iter + 1, ] <- thetaCurr
    thr <- sum((gradCurr)^2)
    
    df <- data.frame(t(thetaCurr))
    names(df) <- paramNodes
    cat(paste0("Iteration Number: ", iter, ".\n",
               "Parameter Estimates:\n"))
    print(df, row.names=FALSE)
    cat(paste0("Effective Sample Size for gradient (raw, min): ", 
               min(effSizesGrad[iter, ]), 
               "\n"))
    cat(paste0("Effective Sample Size for 1D sampling: ", 
               effSizes[iter], "\n"))
    if (iter > 2 * blockSize) {
      runsPass <- checkRuns(paramMatrix[(iter - blockSize + 1):iter, ],
                            runsThreshold)
      if (runsPass) {
        blockPass <- checkBlocks(paramMatrix[(iter - 2 * blockSize + 1):(iter - blockSize), ],
                                 paramMatrix[(iter - blockSize + 1):iter, ],
                                 pValThreshold)
        if (blockPass) break
      }
    }
    if (iter >= maxIter) break
    iter <- iter + 1
  }
  
  if (returnHess) {
    approxHessian <- compiledFuns$computeHess$run(1e-4, postMode, burninFrac)
    return(list(param=na.omit(paramMatrix),
                iter=iter, 
                effSizes=effSizes,
                effSizesGrad=effSizesGrad,
                hess=approxHessian))
  }
  return(list(param=na.omit(paramMatrix),
              iter=iter, 
              effSizes=effSizes,
              effSizesGrad=effSizesGrad))
}

getKernelMode <- function(samples, adjust=1, kern="gaussian", bdwth="nrd0") {
  d <- density(samples, bw=bdwth, kernel=kern, adjust=adjust)
  modeR <- d$x[which.max(d$y)]
  return(modeR)
}